{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run 'Lib.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.utils.generic_utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use GPU 0\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_SIZE = 100\n",
    "\n",
    "# batch and latent size taken from the paper\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "OUT_DIR = 'out/10c'\n",
    "\n",
    "D_ITERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(OUT_DIR): os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wasserstein_1(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_D():\n",
    "\n",
    "    # weights are initlaized from normal distribution with below params\n",
    "    weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "    input_image = Input(shape=(28, 28, 1), name='input_image')\n",
    "\n",
    "    x = Conv2D(\n",
    "        32, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_1',\n",
    "        kernel_initializer=weight_init)(input_image)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        64, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_2',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        128, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_3',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        256, (3, 3),\n",
    "        padding='same',\n",
    "        name='coonv_4',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    features = Flatten()(x)\n",
    "\n",
    "    output_is_fake = Dense(\n",
    "        1,\n",
    "        activation='linear',\n",
    "        name='output_is_fake',\n",
    "        kernel_initializer=weight_init)(features)\n",
    "\n",
    "    output_class = Dense(\n",
    "        10,\n",
    "        activation='softmax',\n",
    "        name='output_class',\n",
    "        kernel_initializer=weight_init)(features)\n",
    "\n",
    "    return Model(\n",
    "        inputs=[input_image], outputs=[output_is_fake, output_class], name='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_G(Z_SIZE=Z_SIZE):\n",
    "    DICT_LEN = 10\n",
    "    EMBEDDING_LEN = Z_SIZE\n",
    "\n",
    "    # class#\n",
    "    input_class = Input(shape=(1, ), dtype='int32', name='input_class')\n",
    "    # encode class# to the same size as Z to use hadamard multiplication later on\n",
    "    e = Embedding(\n",
    "        DICT_LEN, EMBEDDING_LEN,\n",
    "        embeddings_initializer='glorot_uniform')(input_class)\n",
    "    embedded_class = Flatten(name='embedded_class')(e)\n",
    "\n",
    "    # latent var\n",
    "    input_z = Input(shape=(Z_SIZE, ), name='input_z')\n",
    "\n",
    "    # hadamard product\n",
    "    h = multiply([input_z, embedded_class], name='h')\n",
    "\n",
    "    # cnn part\n",
    "    x = Dense(1024)(h)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Dense(128 * 7 * 7)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Reshape((7, 7, 128))(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, (5, 5), padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, (5, 5), padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(1, (2, 2), padding='same', activation='tanh', name='output_generated_image')(x)\n",
    "\n",
    "    return Model(inputs=[input_z, input_class], outputs=x, name='G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "\n",
    "D = create_D()\n",
    "\n",
    "D.compile(\n",
    "    optimizer=RMSprop(lr=0.00005),\n",
    "    loss=[wasserstein_1, 'sparse_categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_z = Input(shape=(Z_SIZE, ), name='input_z_')\n",
    "input_class = Input(shape=(1, ),name='input_class_', dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "\n",
    "G = create_G()\n",
    "\n",
    "# create combined D(G) model\n",
    "# D.trainable = False\n",
    "output_is_fake, output_class = D(G(inputs=[input_z, input_class]))\n",
    "combined = Model(inputs=[input_z, input_class], outputs=[output_is_fake, output_class])\n",
    "combined.get_layer('D').trainable = False # freeze D in generator training faze\n",
    "\n",
    "combined.compile(\n",
    "    optimizer=RMSprop(lr=0.00005),\n",
    "    loss=[wasserstein_1, 'sparse_categorical_crossentropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc80058a048>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc8078734a8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try generating image\n",
    "z = np.random.randn(100).reshape(1, 100)\n",
    "img = G.predict([z, np.array([8])])\n",
    "plt.imshow(img.reshape((28, 28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get our mnist data, and force it to be of shape (..., 28, 28, 1) with\n",
    "# range [-1., 1.]\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "X_test = np.expand_dims(X_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num_samples, test_num_samples = X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_history = defaultdict(list)\n",
    "test_history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_generated_samples(epoch):\n",
    "\n",
    "    # new batch of z's\n",
    "    zz = np.random.normal(0., 1., (100, Z_SIZE))\n",
    "\n",
    "    # new batch of classes [0..9]\n",
    "    generated_classes = np.array(list(range(0, 10)) * 10, dtype=np.int32)\n",
    "\n",
    "    generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "    rr = []\n",
    "    for c in range(10):\n",
    "        rr.append(\n",
    "            np.concatenate(generated_images[c * 10:(1 + c) * 10]).reshape(\n",
    "                280, 28))\n",
    "    img = np.hstack(rr)\n",
    "\n",
    "    plt.imsave(OUT_DIR + '/generated-e%d.png' % epoch, img, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 10\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.5296 - D(G)_loss: 3.6973\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.5290188789367676, -1.1246798038482666, 1.653696894645691]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[3.7075703144073486, 1.2469645738601685, 2.4606072902679443]\n",
      "\n",
      "Epoch 4 / 10\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.2840 - D(G)_loss: -1.1556\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.28333377838134766, -0.09447970241308212, 0.37781307101249695]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.1198318004608154, -1.3749629259109497, 0.25513067841529846]\n",
      "\n",
      "Epoch 8 / 10\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.2360 - D(G)_loss: -0.9822\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.23235726356506348, -0.07584565877914429, 0.30820322036743164]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-0.9859475493431091, -1.1377376317977905, 0.15178953111171722]\n",
      "\n",
      "Epoch 9 / 10\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.2072 - D(G)_loss: -0.6171\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.20543015003204346, -0.07213948667049408, 0.27756938338279724]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-0.6840993165969849, -0.7934298515319824, 0.10933016240596771]\n",
      "\n",
      "Epoch 10 / 10\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.1887 - D(G)_loss: -0.2891\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.18871049582958221, -0.0772707387804985, 0.26598066091537476]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-0.39608192443847656, -0.48854613304138184, 0.0924641564488411]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print('\\nEpoch {} / {}'.format(epoch + 1, EPOCHS))\n",
    "\n",
    "    batches_num = int(train_num_samples / BATCH_SIZE)\n",
    "    progress_bar = Progbar(target=batches_num)\n",
    "\n",
    "    epoch_combined_losses = []\n",
    "    epoch_D_losses = []\n",
    "\n",
    "    for batch_i in range(batches_num):\n",
    "\n",
    "        if len(epoch_D_losses) + len(epoch_combined_losses) > 1:\n",
    "            progress_bar.update(\n",
    "                batch_i,\n",
    "                values=[\n",
    "                        ('D_loss', np.mean(np.array(epoch_D_losses[-10:]), axis=0)[0]),\n",
    "                        ('D(G)_loss', np.mean(np.array(epoch_combined_losses[-10:]),axis=0)[0])\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            progress_bar.update(batch_i)\n",
    "            \n",
    "        # 1: train D on real+generated images\n",
    "        \n",
    "        for d_it in range(D_ITERS):\n",
    "\n",
    "            # clip D weights\n",
    "\n",
    "            for l in D.layers:\n",
    "                weights = l.get_weights()\n",
    "                weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "                l.set_weights(weights)\n",
    "\n",
    "            # create batches of images and labels\n",
    "            real_images = X_train[batch_i * BATCH_SIZE:(batch_i + 1) * BATCH_SIZE]\n",
    "            real_images_classes = y_train[batch_i * BATCH_SIZE:(batch_i + 1) * BATCH_SIZE]\n",
    "\n",
    "            # new batch of z's\n",
    "            zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE))\n",
    "\n",
    "            # new batch of classes [0..9]\n",
    "            generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "\n",
    "            generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "            X = np.concatenate((real_images, generated_images))\n",
    "            y_is_fake = np.array([-1] * BATCH_SIZE + [1] * BATCH_SIZE) # [is_fake=-1xBATCH_SIZE, 1xBATCH_SIZE]\n",
    "            y_classes = np.concatenate((real_images_classes, generated_classes))\n",
    "\n",
    "            # train \n",
    "            D_losses = D.train_on_batch(X, [y_is_fake, y_classes])\n",
    "            epoch_D_losses.append(D_losses)\n",
    "        \n",
    "        # 2: train D(G) (only G is trainable)\n",
    "        \n",
    "        # 2x so G is trained for the same number of images\n",
    "        # as D above (which is trained on real+generated)\n",
    "        zz = np.random.normal(0., 1., (2 * BATCH_SIZE, Z_SIZE)) \n",
    "        generated_classes = np.random.randint(0, 10, 2 * BATCH_SIZE)\n",
    "\n",
    "        y_is_fake = -np.ones(2 * BATCH_SIZE) # all not-fake\n",
    "\n",
    "        combined_losses = combined.train_on_batch(\n",
    "            [zz, generated_classes.reshape((-1, 1))],\n",
    "            [y_is_fake, generated_classes])\n",
    "        \n",
    "        epoch_combined_losses.append(combined_losses)\n",
    "        \n",
    "    print('\\nD:', D.metrics_names)\n",
    "    print(np.mean(np.array(epoch_D_losses), axis=0).tolist())\n",
    "    \n",
    "    print('D(G):', combined.metrics_names)\n",
    "    print(np.mean(np.array(epoch_combined_losses), axis=0).tolist())\n",
    "    \n",
    "    save_generated_samples(epoch)"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Keras  WACGAN",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
