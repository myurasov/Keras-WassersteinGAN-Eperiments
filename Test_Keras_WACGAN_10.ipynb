{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.utils.generic_utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GPU = \"0\"\n",
    "RUN = '10'\n",
    "OUT_DIR = 'out/' + RUN\n",
    "TENSORBOARD_DIR = '/tensorboard/wgans/' + RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# latent vector size\n",
    "Z_SIZE = 100\n",
    "\n",
    "# number of iterations D is trained for per each G iteration\n",
    "D_ITERS = 5\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use specific GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(OUT_DIR): os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basically return mean(y_pred),\n",
    "# but with ability to inverse it for minimization (when y_true == -1)\n",
    "def wasserstein_dist(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_D():\n",
    "\n",
    "    # weights are initlaized from normal distribution with below params\n",
    "    weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "    input_image = Input(shape=(28, 28, 1), name='input_image')\n",
    "\n",
    "    x = Conv2D(\n",
    "        32, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_1',\n",
    "        kernel_initializer=weight_init)(input_image)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        64, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_2',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        128, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_3',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        256, (3, 3),\n",
    "        padding='same',\n",
    "        name='coonv_4',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    features = Flatten()(x)\n",
    "\n",
    "    output_is_fake = Dense(\n",
    "        1, activation='linear', name='output_is_fake')(features)\n",
    "\n",
    "    output_class = Dense(\n",
    "        10, activation='softmax', name='output_class')(features)\n",
    "\n",
    "    return Model(\n",
    "        inputs=[input_image], outputs=[output_is_fake, output_class], name='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_G(Z_SIZE=Z_SIZE):\n",
    "    DICT_LEN = 10\n",
    "    EMBEDDING_LEN = Z_SIZE\n",
    "\n",
    "    # weights are initlaized from normal distribution with below params\n",
    "    weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "    # class#\n",
    "    input_class = Input(shape=(1, ), dtype='int32', name='input_class')\n",
    "    # encode class# to the same size as Z to use hadamard multiplication later on\n",
    "    e = Embedding(\n",
    "        DICT_LEN, EMBEDDING_LEN,\n",
    "        embeddings_initializer='glorot_uniform')(input_class)\n",
    "    embedded_class = Flatten(name='embedded_class')(e)\n",
    "\n",
    "    # latent var\n",
    "    input_z = Input(shape=(Z_SIZE, ), name='input_z')\n",
    "\n",
    "    # hadamard product\n",
    "    h = multiply([input_z, embedded_class], name='h')\n",
    "\n",
    "    # cnn part\n",
    "    x = Dense(1024)(h)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Dense(128 * 7 * 7)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Reshape((7, 7, 128))(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, (5, 5), padding='same', kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, (5, 5), padding='same', kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        1, (2, 2),\n",
    "        padding='same',\n",
    "        activation='tanh',\n",
    "        name='output_generated_image',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "\n",
    "    return Model(inputs=[input_z, input_class], outputs=x, name='G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "\n",
    "D = create_D()\n",
    "\n",
    "D.compile(\n",
    "    optimizer=RMSprop(lr=0.00005),\n",
    "    loss=[wasserstein_dist, 'sparse_categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_z = Input(shape=(Z_SIZE, ), name='input_z_')\n",
    "input_class = Input(shape=(1, ),name='input_class_', dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "\n",
    "G = create_G()\n",
    "\n",
    "# create combined D(G) model\n",
    "# D.trainable = False\n",
    "output_is_fake, output_class = D(G(inputs=[input_z, input_class]))\n",
    "DG = Model(inputs=[input_z, input_class], outputs=[output_is_fake, output_class])\n",
    "DG.get_layer('D').trainable = False # freeze D in generator training faze\n",
    "\n",
    "DG.compile(\n",
    "    optimizer=RMSprop(lr=0.00005),\n",
    "    loss=[wasserstein_dist, 'sparse_categorical_crossentropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe464346908>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe46a636710>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try generating image\n",
    "z = np.random.randn(100).reshape(1, 100)\n",
    "img = G.predict([z, np.array([8])])\n",
    "plt.imshow(img.reshape((28, 28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get our mnist data, and force it to be of shape (..., 28, 28, 1) with\n",
    "# range [-1., 1.]\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "X_test = np.expand_dims(X_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num_samples, test_num_samples = X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_history = defaultdict(list)\n",
    "test_history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_generated_samples(epoch):\n",
    "\n",
    "    # new batch of z's\n",
    "    zz = np.random.normal(0., 1., (100, Z_SIZE))\n",
    "\n",
    "    # new batch of classes [0..9]\n",
    "    generated_classes = np.array(list(range(0, 10)) * 10, dtype=np.int32)\n",
    "\n",
    "    generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "    rr = []\n",
    "    for c in range(10):\n",
    "        rr.append(\n",
    "            np.concatenate(generated_images[c * 10:(1 + c) * 10]).reshape(\n",
    "                280, 28))\n",
    "    img = np.hstack(rr)\n",
    "\n",
    "    plt.imsave(OUT_DIR + '/generated-e%d.png' % epoch, img, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 100\n",
      "599/600 [============================>.] - ETA: 0s - D1_is_fake: -68.5461 - D1_class: 1.6644 - D2_is_fake: 44.1182 - D2_class: 2.5012 - D(G)_is_fake: -40.8354 - D(G)_class: 2.4842\n",
      "Epoch 2 / 100\n",
      "599/600 [============================>.] - ETA: 0s - D1_is_fake: -19.4639 - D1_class: 1.6362 - D2_is_fake: 17.2079 - D2_class: 2.4188 - D(G)_is_fake: -15.6331 - D(G)_class: 2.4056\n",
      "Epoch 3 / 100\n",
      "599/600 [============================>.] - ETA: 0s - D1_is_fake: -6.2792 - D1_class: 1.5616 - D2_is_fake: 4.0109 - D2_class: 2.3794 - D(G)_is_fake: -3.4337 - D(G)_class: 2.3597\n",
      "Epoch 4 / 100\n",
      "599/600 [============================>.] - ETA: 0s - D1_is_fake: -12.0242 - D1_class: 1.3020 - D2_is_fake: 10.9094 - D2_class: 2.3978 - D(G)_is_fake: -10.0335 - D(G)_class: 2.3683\n",
      "Epoch 5 / 100\n",
      "599/600 [============================>.] - ETA: 0s - D1_is_fake: -4.2000 - D1_class: 1.2238 - D2_is_fake: 3.2507 - D2_class: 2.3860 - D(G)_is_fake: -2.7847 - D(G)_class: 2.3629\n",
      "Epoch 6 / 100\n",
      "599/600 [============================>.] - ETA: 0s - D1_is_fake: -5.6468 - D1_class: 1.2172 - D2_is_fake: 5.1711 - D2_class: 2.3086 - D(G)_is_fake: -4.7175 - D(G)_class: 2.2827\n",
      "Epoch 7 / 100\n",
      "599/600 [============================>.] - ETA: 0s - D1_is_fake: -3.5501 - D1_class: 1.1003 - D2_is_fake: 3.6511 - D2_class: 1.8187 - D(G)_is_fake: -3.3019 - D(G)_class: 1.7849\n",
      "Epoch 8 / 100\n",
      "599/600 [============================>.] - ETA: 0s - D1_is_fake: -1.7800 - D1_class: 0.7817 - D2_is_fake: 1.7636 - D2_class: 0.9630 - D(G)_is_fake: -1.5038 - D(G)_class: 0.9216\n",
      "Epoch 9 / 100\n",
      "599/600 [============================>.] - ETA: 0s - D1_is_fake: -0.5597 - D1_class: 0.6235 - D2_is_fake: 0.4796 - D2_class: 0.5401 - D(G)_is_fake: -0.2760 - D(G)_class: 0.5124\n",
      "Epoch 10 / 100\n",
      "599/600 [============================>.] - ETA: 0s - D1_is_fake: 0.0562 - D1_class: 0.5550 - D2_is_fake: -0.0308 - D2_class: 0.2741 - D(G)_is_fake: 0.2045 - D(G)_class: 0.2553\n",
      "Epoch 11 / 100\n",
      "295/600 [=============>................] - ETA: 226s - D1_is_fake: -0.0510 - D1_class: 0.4727 - D2_is_fake: 0.1812 - D2_class: 0.0648 - D(G)_is_fake: -0.0252 - D(G)_class: 0.0627"
     ]
    }
   ],
   "source": [
    "# fake = 1\n",
    "# real = -1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print('\\nEpoch {} / {}:'.format(epoch + 1, EPOCHS))\n",
    "\n",
    "    batches_num = int(train_num_samples / BATCH_SIZE)\n",
    "    progress_bar = Progbar(target=batches_num)\n",
    "\n",
    "    epoch_DG_losses = []\n",
    "    epoch_D1_losses = []\n",
    "    epoch_D2_losses = []\n",
    "\n",
    "    for batch_i in range(batches_num):\n",
    "\n",
    "        if len(epoch_D1_losses) > 0:\n",
    "            progress_bar.update(\n",
    "                batch_i,\n",
    "                values=[\n",
    "                        ('D1_is_fake', np.mean(epoch_D1_losses[-5:], axis=0)[1]),\n",
    "                        ('D1_class', np.mean(epoch_D1_losses[-5:], axis=0)[2]),\n",
    "                        ('D2_is_fake', np.mean(epoch_D2_losses[-5:], axis=0)[1]),\n",
    "                        ('D2_class', np.mean(epoch_D2_losses[-5:], axis=0)[2]),\n",
    "                        ('D(G)_is_fake', np.mean(epoch_DG_losses[-5:],axis=0)[1]),\n",
    "                        ('D(G)_class', np.mean(epoch_DG_losses[-5:],axis=0)[2])\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            progress_bar.update(batch_i)\n",
    "            \n",
    "        # 1: train D on real+generated images\n",
    "        \n",
    "        if batch_i < 25 or batch_i % 500 == 0:\n",
    "            d_iters = 100\n",
    "        else:\n",
    "            d_iters = D_ITERS\n",
    "        \n",
    "        for d_it in range(d_iters):\n",
    "            \n",
    "            D.trainable = True\n",
    "            for l in D.layers: l.trainable = True\n",
    "\n",
    "            # clip D weights\n",
    "\n",
    "            for l in D.layers:\n",
    "                weights = l.get_weights()\n",
    "                weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "                l.set_weights(weights)\n",
    "\n",
    "            # 1.1: maximize D output on reals === minimize -1*(D(real))\n",
    "            real_images = X_train[batch_i * BATCH_SIZE:(batch_i + 1) * BATCH_SIZE]\n",
    "            real_images_classes = y_train[batch_i * BATCH_SIZE:(batch_i + 1) * BATCH_SIZE]\n",
    "            \n",
    "            D_loss = D.train_on_batch(real_images, [-np.ones(BATCH_SIZE), real_images_classes])\n",
    "            epoch_D1_losses.append(D_loss)\n",
    "\n",
    "            # 1.2: minimize D output on fakes \n",
    "\n",
    "            zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE))\n",
    "            generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "            generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "            \n",
    "            D_loss = D.train_on_batch(generated_images, [np.ones(BATCH_SIZE), generated_classes])\n",
    "            epoch_D2_losses.append(D_loss)\n",
    "            \n",
    "        # 2: train D(G) (D is frozen)\n",
    "        # minimize D output while supplying it with fakes, telling it that they are reals (-1)\n",
    "\n",
    "        D.trainable = False\n",
    "        for l in D.layers: l.trainable = False\n",
    "        \n",
    "        zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE)) \n",
    "        generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "\n",
    "        DG_loss = DG.train_on_batch(\n",
    "            [zz, generated_classes.reshape((-1, 1))],\n",
    "            [-np.ones(BATCH_SIZE), generated_classes])\n",
    "        \n",
    "        epoch_DG_losses.append(DG_loss)\n",
    "    \n",
    "    save_generated_samples(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Keras  WACGAN",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
