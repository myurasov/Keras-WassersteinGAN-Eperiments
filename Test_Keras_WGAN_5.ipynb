{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ More updates of D\n",
    "+ Implicit weight clipping of D\n",
    "+ Closer to vanilla WGAN per https://arxiv.org/pdf/1701.07875.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run 'Lib.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = 'out_5'\n",
    "import os\n",
    "if not os.path.isdir(OUT_DIR): os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils.generic_utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_SIZE = 100\n",
    "\n",
    "# batch and latent size taken from the paper\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Adam parameters suggested in https://arxiv.org/abs/1511.06434\n",
    "ADAM_LR = 0.0002\n",
    "ADAM_BETA_1 = 0.5\n",
    "\n",
    "# how many times to train D per each G(D) update\n",
    "# 5 is suggested in https://arxiv.org/pdf/1701.07875.pdf\n",
    "D_TRAIN_ITERATIONS = 5\n",
    "\n",
    "# D weight clipping per https://arxiv.org/pdf/1701.07875.pdf\n",
    "D_WEIGHTS_LOWER_BOUND = -0.01\n",
    "D_WEIGHTS_UPPER_BOUND = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wasserstein_distance(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_D():\n",
    "    input_image = Input(shape=(28, 28, 1), name='input_image')\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='same', name='conv_1')(input_image)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='conv_2')(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='conv_3')(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='coonv_4')(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    features = Flatten()(x)\n",
    "\n",
    "    output_is_fake = Dense(\n",
    "        1, activation='linear', name='output_is_fake')(features)\n",
    "    output_class = Dense(\n",
    "        10, activation='softmax', name='output_class')(features)\n",
    "\n",
    "    return Model(inputs=[input_image], outputs=[output_is_fake, output_class], name='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_G(Z_SIZE=Z_SIZE):\n",
    "    DICT_LEN = 10\n",
    "    EMBEDDING_LEN = Z_SIZE\n",
    "\n",
    "    # class#\n",
    "    input_class = Input(shape=(1, ), dtype='int32', name='input_class')\n",
    "    # encode class# to the same size as Z to use hadamard multiplication later on\n",
    "    e = Embedding(\n",
    "        DICT_LEN, EMBEDDING_LEN,\n",
    "        embeddings_initializer='glorot_uniform')(input_class)\n",
    "    embedded_class = Flatten(name='embedded_class')(e)\n",
    "\n",
    "    # latent var\n",
    "    input_z = Input(shape=(Z_SIZE, ), name='input_z')\n",
    "\n",
    "    # hadamard product\n",
    "    h = multiply([input_z, embedded_class], name='h')\n",
    "\n",
    "    # cnn part\n",
    "    x = Dense(1024)(h)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Dense(128 * 7 * 7)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Reshape((7, 7, 128))(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, (5, 5), padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, (5, 5), padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(1, (2, 2), padding='same', activation='tanh', name='output_generated_image')(x)\n",
    "\n",
    "    return Model(inputs=[input_z, input_class], outputs=x, name='G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = create_D()\n",
    "\n",
    "# SGD without momentum, see\n",
    "# https://github.com/shekkizh/WassersteinGAN.tensorflow#observations\n",
    "D.compile(\n",
    "    optimizer=SGD(nesterov=False), \n",
    "    loss=[wasserstein_distance, 'sparse_categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = create_G()\n",
    "\n",
    "G.compile(\n",
    "    optimizer=Adam(lr=ADAM_LR, beta_1=ADAM_BETA_1), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_z = Input(shape=(Z_SIZE, ), name='input_z_')\n",
    "input_class = Input(shape=(1, ),name='input_class_', dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create combined D(G) model\n",
    "# D.trainable = False\n",
    "output_is_fake, output_class = D(G(inputs=[input_z, input_class]))\n",
    "combined = Model(inputs=[input_z, input_class], outputs=[output_is_fake, output_class])\n",
    "combined.get_layer('D').trainable = False # freeze D in generator training faze\n",
    "\n",
    "combined.compile(\n",
    "    optimizer='RMSprop',\n",
    "    loss=[wasserstein_distance, 'sparse_categorical_crossentropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try generating image\n",
    "\n",
    "z = np.random.randn(100).reshape(1, 100)\n",
    "img = G.predict([z, np.array([8])])\n",
    "plt.imshow(img.reshape((28, 28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get our mnist data, and force it to be of shape (..., 28, 28, 1) with\n",
    "# range [-1., 1.]\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "X_test = np.expand_dims(X_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[777].reshape((28, 28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num_samples, test_num_samples = X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_history = defaultdict(list)\n",
    "test_history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_generated_samples(epoch, G):\n",
    "\n",
    "    # new batch of z's\n",
    "    zz = np.random.normal(0., 1., (100, Z_SIZE))\n",
    "\n",
    "    # new batch of classes [0..9]\n",
    "    generated_classes = np.random.randint(0, 10, 100)\n",
    "\n",
    "    generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "    rr = []\n",
    "    for c in range(10):\n",
    "        rr.append(np.concatenate(generated_images[c * 10:(1 + c) * 10]).reshape(280, 28))\n",
    "    img = np.hstack(rr)\n",
    "\n",
    "    plt.imsave(OUT_DIR + '/generated-e%d.png'%epoch, img, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print('\\nEpoch {} / {}'.format(epoch + 1, EPOCHS))\n",
    "\n",
    "    batches_num = int(train_num_samples / BATCH_SIZE)\n",
    "    progress_bar = Progbar(target=batches_num)\n",
    "\n",
    "    epoch_combined_losses = []\n",
    "    epoch_D_losses = []\n",
    "\n",
    "    for batch_i in range(batches_num):\n",
    "\n",
    "        if len(epoch_D_losses) + len(epoch_combined_losses) > 1:\n",
    "            progress_bar.update(\n",
    "                batch_i,\n",
    "                values=[\n",
    "                        ('D_loss', np.mean(np.array(epoch_D_losses), axis=0)[0]),\n",
    "                        ('D(G)_loss', np.mean(np.array(epoch_combined_losses),axis=0)[0])\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            progress_bar.update(batch_i)\n",
    "            \n",
    "        # 1: train D on real+generated images\n",
    "        \n",
    "        for d_it in range(D_TRAIN_ITERATIONS):\n",
    "\n",
    "            # create batches of images and labels\n",
    "            real_images = X_train[batch_i * BATCH_SIZE:(batch_i + 1) * BATCH_SIZE]\n",
    "            real_images_classes = y_train[batch_i * BATCH_SIZE:(batch_i + 1) * BATCH_SIZE]\n",
    "\n",
    "            # new batch of z's\n",
    "            zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE))\n",
    "\n",
    "            # new batch of classes [0..9]\n",
    "            generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "\n",
    "            generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "            X = np.concatenate((real_images, generated_images))\n",
    "            y_is_fake = np.array([-1] * BATCH_SIZE + [1] * BATCH_SIZE) # [is_fake=-1xBATCH_SIZE, 1xBATCH_SIZE]\n",
    "            y_classes = np.concatenate((real_images_classes, generated_classes))\n",
    "\n",
    "            # train \n",
    "            D_losses = D.train_on_batch(X, [y_is_fake, y_classes])\n",
    "            epoch_D_losses.append(D_losses)\n",
    "\n",
    "            # clip D weights\n",
    "\n",
    "            for l in D.layers:\n",
    "                weights = l.get_weights()\n",
    "                weights = [np.clip(w, D_WEIGHTS_LOWER_BOUND, D_WEIGHTS_UPPER_BOUND) for w in weights]\n",
    "                l.set_weights(weights)\n",
    "        \n",
    "        \n",
    "        # 2: train D(G) (only G is trainable)\n",
    "        \n",
    "        # xxx (2 * D_TRAIN_ITERATIONS) so G is trained for the same number of images\n",
    "        # xxx as D above (which is trained on real+generated)\n",
    "        zz = np.random.normal(0., 1.,  (BATCH_SIZE, Z_SIZE))\n",
    "        generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "\n",
    "        y_is_fake = -np.ones(2 * BATCH_SIZE) # all not-fake\n",
    "\n",
    "        combined_losses = combined.train_on_batch(\n",
    "            [zz, generated_classes.reshape((-1, 1))],\n",
    "            [y_is_fake, generated_classes])\n",
    "        \n",
    "        epoch_combined_losses.append(combined_losses)\n",
    "        \n",
    "    print('\\nD:', D.metrics_names)\n",
    "    print(np.mean(np.array(epoch_D_losses), axis=0).tolist())\n",
    "    \n",
    "    print('D(G):', combined.metrics_names)\n",
    "    print(np.mean(np.array(epoch_combined_losses), axis=0).tolist())\n",
    "    \n",
    "    save_generated_samples(epoch, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clamp_lower = -0.1\n",
    "# clamp_upper = 0.1\n",
    "\n",
    "# # Clip discriminator weights\n",
    "# for l in D.layers:\n",
    "#     weights = l.get_weights()\n",
    "#     weights = [np.clip(w, clamp_lower, clamp_upper) for w in weights]\n",
    "#     l.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Keras  WACGAN",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
