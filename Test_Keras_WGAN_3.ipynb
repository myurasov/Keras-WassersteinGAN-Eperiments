{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run 'Lib.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘out’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "%mkdir 'out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import *\n",
    "from keras.backend.common import _EPSILON\n",
    "from keras.utils.generic_utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_SIZE = 100\n",
    "\n",
    "# batch and latent size taken from the paper\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Adam parameters suggested in https://arxiv.org/abs/1511.06434\n",
    "ADAM_LR = 0.0002\n",
    "ADAM_BETA_1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ???\n",
    "def modified_binary_crossentropy(y_true, y_pred):\n",
    "#     output = K.clip(output, _EPSILON, 1.0 - _EPSILON)\n",
    "#     return -(target * output + (1.0 - target) * (1.0 - output))\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_D():\n",
    "    input_image = Input(shape=(28, 28, 1), name='input_image')\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='same', name='conv_1')(input_image)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='conv_2')(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='conv_3')(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='coonv_4')(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    features = Flatten()(x)\n",
    "\n",
    "    output_is_fake = Dense(\n",
    "        1, activation='linear', name='output_is_fake')(features)\n",
    "    output_class = Dense(\n",
    "        10, activation='softmax', name='output_class')(features)\n",
    "\n",
    "    return Model(inputs=[input_image], outputs=[output_is_fake, output_class], name='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_G(Z_SIZE=Z_SIZE):\n",
    "    DICT_LEN = 10\n",
    "    EMBEDDING_LEN = Z_SIZE\n",
    "\n",
    "    # class#\n",
    "    input_class = Input(shape=(1, ), dtype='int32', name='input_class')\n",
    "    # encode class# to the same size as Z to use hadamard multiplication later on\n",
    "    e = Embedding(\n",
    "        DICT_LEN, EMBEDDING_LEN,\n",
    "        embeddings_initializer='glorot_uniform')(input_class)\n",
    "    embedded_class = Flatten(name='embedded_class')(e)\n",
    "\n",
    "    # latent var\n",
    "    input_z = Input(shape=(Z_SIZE, ), name='input_z')\n",
    "\n",
    "    # hadamard product\n",
    "    h = multiply([input_z, embedded_class], name='h')\n",
    "\n",
    "    # cnn part\n",
    "    x = Dense(1024)(h)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Dense(128 * 7 * 7)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Reshape((7, 7, 128))(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, (5, 5), padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, (5, 5), padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(1, (2, 2), padding='same', activation='tanh', name='output_generated_image')(x)\n",
    "\n",
    "    return Model(inputs=[input_z, input_class], outputs=x, name='G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = create_D()\n",
    "\n",
    "D.compile(\n",
    "    optimizer=SGD(clipvalue=0.01),\n",
    "    loss=[modified_binary_crossentropy, 'sparse_categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = create_G()\n",
    "\n",
    "G.compile(\n",
    "    optimizer=Adam(lr=ADAM_LR, beta_1=ADAM_BETA_1), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_z = Input(shape=(Z_SIZE, ), name='input_z_')\n",
    "input_class = Input(shape=(1, ),name='input_class_', dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create combined D(G) model\n",
    "# D.trainable = False\n",
    "output_is_fake, output_class = D(G(inputs=[input_z, input_class]))\n",
    "combined = Model(inputs=[input_z, input_class], outputs=[output_is_fake, output_class])\n",
    "combined.get_layer('D').trainable = False # freeze D in generator training faze\n",
    "\n",
    "combined.compile(\n",
    "    optimizer='RMSprop',\n",
    "    loss=[modified_binary_crossentropy, 'sparse_categorical_crossentropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f70c04acf98>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAIABJREFUeJzt3Xtw3Xd55/HPI1myfJNkyRdZjmPZSZw0hVxpkyZDyGVg\nQxkgkGSXPwoZhnQoW5aGhoWdQqi57Ax/7JRrFzqFbWaSmQ2dMEmHbRpYSEgCIWWSkHjBSZzg+92y\nrJutu7/7x/kpCCNZ9vc51k9+9H7NaI51znnO8/VPP52PftI5v8dSSgIAADHVlL0AAABw5hD0AAAE\nRtADABAYQQ8AQGAEPQAAgRH0AAAERtADABAYQQ8AQGAEPQAAgRH0AAAERtADABAYQQ8AQGAEPQAA\ngRH0AAAERtADABAYQQ8AQGDzyl7AmWBm2yQ1Stpe8lIAAMjVIak3pbTO8yAhg15SY11dXUtbW1tL\n7gOMjIxkN6+trc2ulaSxsbFSaiWprq4uu3Z0dLS03p5aSTp+/Hh27bx5vm8jT29PrSTV19eX1tu7\nv3jqa2p8v8z0fI97v0c9+5vneU2ShoeHs2vNzNXbo8zenv20u7vbvb9IJQe9mZ0j6fOSbpbUKmmf\npIclfS6ldMTx0Nvb2tpaPvnJT2Y/wIEDB7JrGxsbs2slqaenJ7u2r6/P1Xv58uXZtV1dXa7eK1eu\nzK5tb2939fY8gTU3N7t6Dw0NZdcODAy4enu22+DgoKu3d3/xfI82NDS4ere0ZB9DqLe319V72bJl\n2bX79u1z9d6xY0d2rfcHYs8PZ96g99QfOZIfZQ899JAOHz68PfsBCqUFvZmdJ+lpSSsk/YuklyX9\nsaS/knSzmV2bUjpc1voAAIigzBfj/U9VQv5jKaVbUkr/LaV0o6QvS7pQ0n8vcW0AAIRQStAXR/Nv\nU+XFcn9/ws1/K+mopPeb2aIZXhoAAKGUdUR/Q3H5w5TS77yiJ6XUJ+lnkhZKunqmFwYAQCRl/Y3+\nwuJyyxS3v6rKEf8GST+e6kHM7Lkpbroof2kAAMRR1hF9U3E51cvLx6/3vZwZAIA57qx+H31K6crJ\nri+O9K+Y4eUAADDrlHVEP37E3jTF7ePXd8/AWgAACKusoH+luNwwxe0XFJdT/Q0fAACcgrKC/vHi\n8m1m9jtrMLMlkq6VdEzSMzO9MAAAIikl6FNKv5H0Q1VO2P+XJ9z8OUmLJN2XUjo6w0sDACCUMl+M\n959VOQXu18zsJkkvSbpKlffYb5H06RLXBgBACKWdArc4qn+TpHtVCfi7JZ0n6auSruY89wAA+JX6\n9rqU0i5JHyxzDQAARHZWv4/+ZMxMCxYsyK6fP39+du2aNWuyayXf2NLt27e7envG3O7cudPVe926\nddm1S5YscfVua2vLru3v73f13rNnT3at9//9yiuvTH+nKSxcuNDV27PNJenXv/51dq1nJLLke35I\nKbl6e8bUHj9+fPo7nYRnzK1nBLbk+z7xjKGWfF+zasyT9ypzeh0AADjDCHoAAAIj6AEACIygBwAg\nMIIeAIDACHoAAAIj6AEACIygBwAgMIIeAIDACHoAAAIj6AEACIygBwAgMIIeAIDACHoAAAILO6Z2\nZGREu3btyq73jETs6OjIrpWk1tbW7Nr6+npX79ra2uza7u5uV2/PWGHvuNYVK1Zk1zY2Nrp6e8bc\ntre3u3p3dnZm1/b29rp6Hzp0yFXv+R719vZ8n23evNnV+/nnn8+u9Xx/S77ttmjRIlfvefPy46qm\nxndMe/To0exaz//bu+7XH6cqjwIAAGYlgh4AgMAIegAAAiPoAQAIjKAHACAwgh4AgMAIegAAAiPo\nAQAIjKAHACAwgh4AgMAIegAAAiPoAQAIjKAHACAwgh4AgMAIegAAAgs7j97M1NDQkF1fV1eXXbt9\n+/bsWsk3W72rq8vV2zP/eP369a7ennnTnln2kjQ8PJxda2au3p79dPHixa7eL774Ynatd7a5d7uN\njIxk13rmyUvS4cOHs2u7u7tdvT0z4b3zzQcGBrJrPeuWfF8z79f7yJEj2bWtra3ZtcyjBwAA0yLo\nAQAIjKAHACAwgh4AgMAIegAAAiPoAQAIjKAHACAwgh4AgMAIegAAAiPoAQAIjKAHACAwgh4AgMAI\negAAAiPoAQAILOyY2tHRUR08eLDsZWRZuXJldu0VV1zh6r1r167sWu/YUc/4Ts+4VUlau3Ztdm1b\nW5ur9zPPPOOq9+jr68uu9Y7Q9IzvlKTGxsbsWu94X8//fdmyZa7enrWvWrXK1dszDtoz+lvyjcjd\nu3evq3dPT0927YoVK1y9q4EjegAAAiPoAQAIjKAHACAwgh4AgMAIegAAAiPoAQAIjKAHACAwgh4A\ngMAIegAAAiPoAQAIjKAHACAwgh4AgMAIegAAAiPoAQAIjKAHACCwsPPozUzz5uX/9zzzpru6urJr\nJam2tja7tqWlxdXb8/9euHChq7dnuw0ODrp6P//889m1F198sav36Ohodu2OHTtcvT2Gh4dd9Wbm\nqn/jG9+YXbt//35Xb8/XbPXq1a7eIyMj2bVr1qxx9a6vr8+u9Ty3SL7nB+++mlLKrl2yZEl2rXeb\nvf44VXmUDGa23czSFB++70IAACCp/CP6HklfmeT6/pleCAAAEZUd9N0ppY0lrwEAgLB4MR4AAIGV\nfUQ/38z+TNK5ko5K2iTpyZTSWLnLAgAghrKDvk3SfSdct83MPphSemK6YjN7boqbLnKvDACAAMr8\n1f0/SbpJlbBfJOmNkv5BUoekfzOzS8tbGgAAMZR2RJ9S+twJV/1K0l+YWb+kuyVtlPSeaR7jysmu\nL470r6jCMgEAOKvNxhfjfau4vK7UVQAAEMBsDPpDxeWiUlcBAEAAszHory4ut5a6CgAAAigl6M3s\nD8zs947YzaxD0jeKT++fyTUBABBRWS/G+0+S7jazJyXtkNQn6TxJ75DUIOkRSf+jpLUBABBGWUH/\nuKQLJV0u6VpV/h7fLemnqryv/r7kGRcEAAAklRT0xclwpj0hjkdNTY1rPKDn5wzv6NC9e/e66j02\nb96cXXvOOee4evf29mbXHjlyxNV76dKl2bXPPvusq/fy5cuzaxcsWODqffTo0exa70jkgYEBV/3Y\nWP4JND1fb0nq7OzMrvV+zVatWpVd6xkzK/m+5n19fa7e3d3d2bWescKStGLFiuza5ubm7FrPyPKJ\nZuOL8QAAQJUQ9AAABEbQAwAQGEEPAEBgBD0AAIER9AAABEbQAwAQGEEPAEBgBD0AAIER9AAABEbQ\nAwAQGEEPAEBgBD0AAIER9AAABEbQAwAQWCnz6GfC2NiYenp6susPHTqUXTsyMpJdK0nHjh3Lrl23\nbp2r9/r167NrV69e7er9m9/8JrvWM8tektrb27NrDx8+7OpdV1eXXbto0SJXb8+cbs88eEk6evSo\nq96z3VeuXOnq7ZkJv2TJElfvZcuWZdeamav30NBQdq3nOVWSBgcHs2s920zyPSfX1OQfT3u/Xq+v\noSqPAgAAZiWCHgCAwAh6AAACI+gBAAiMoAcAIDCCHgCAwAh6AAACI+gBAAiMoAcAIDCCHgCAwAh6\nAAACI+gBAAiMoAcAIDCCHgCAwMKOqa2pqVF9fX12fXNzc3atd7Tgrl27smsHBgZcvT3b7OKLL3b1\nLnM0cEdHR3bthRde6OrtGTXb19fn6u0Z13rkyBFX7+PHj7vqV6xYkV3r+R6TfCNy58+f7+r98ssv\nZ9decsklrt4bNmzIrt2zZ4+rt2df9YwVlqSXXnrJVV82jugBAAiMoAcAIDCCHgCAwAh6AAACI+gB\nAAiMoAcAIDCCHgCAwAh6AAACI+gBAAiMoAcAIDCCHgCAwAh6AAACI+gBAAiMoAcAIDCCHgCAwMLO\nox8ZGdH+/fuz67u7u7Nr6+rqsmsl37xqz7ol6eDBg9m169atc/X2zJT3zHSXpJaWluxaz1x0r/b2\ndlf94OBglVZy+rzz6Ds7O7Nr+/v7Xb1ra2tLqZWk5ubm7Nr6+npX746OjuzaF154wdW7pib/uNT7\nnLx79+7s2ra2tuxaM8uunYgjegAAAiPoAQAIjKAHACAwgh4AgMAIegAAAiPoAQAIjKAHACAwgh4A\ngMAIegAAAiPoAQAIjKAHACAwgh4AgMAIegAAAiPoAQAILOyY2traWjU2NmbXe0bcDg8PZ9dKvlGz\nntGdkrR27drsWu/4Tc+4V+/YUY+jR4+66pcuXZpd6x07um3btuzavr4+V2/v6FDP2NINGza4eo+N\njWXXekdJe8b77tq1y9XbU+/9Hm1oaMiuXb58uav3ueeem13rGTs+q8bUmtltZvZ1M3vKzHrNLJnZ\n/dPUXGNmj5hZl5kNmNkmM7vLzHxpAQAAXletI/rPSLpUUr+k3ZIuOtmdzezdkr4naVDSdyV1SXqn\npC9LulbS7VVaFwAAc1q1/kb/cUkbJDVK+sjJ7mhmjZL+UdKYpOtTSh9KKf1XSZdJ+rmk28zsfVVa\nFwAAc1pVgj6l9HhK6dWUUjqFu98mabmkB1JKz054jEFVfjMgTfPDAgAAODVlvOr+xuLy0Ulue1LS\nMUnXmFn+KxgAAICkcoL+wuJyy4k3pJRGJW1T5bUD62dyUQAARFTG2+uaisueKW4fv755ugcys+em\nuOmkLwYEAGCu4IQ5AAAEVsYR/fgRe9MUt49fP+1ZJVJKV052fXGkf8XpLw0AgFjKOKJ/pbj8vVNT\nmdk8SeskjUraOpOLAgAgojKC/rHi8uZJbrtO0kJJT6eUhmZuSQAAxFRG0D8oqVPS+8zsTeNXmlmD\npC8Wn36zhHUBABBOVf5Gb2a3SLql+LStuPwTM7u3+HdnSukTkpRS6jWzP1cl8H9iZg+ocgrcd6ny\n1rsHVTktLgAAcKrWi/Euk3THCdet12/fC79D0ifGb0gpPWxmb5H0aUm3SmqQ9Jqkv5b0tVM8wx4A\nAJhGVYI+pbRR0sbTrPmZpD+tRn8AADC5sPPoU0qumdHLli1z9fbwzPlubGx09R4cHMyu3brV90YJ\nT++2trbp73QSAwMD2bXe+eJ79uzJrj106JCr96uvvppdW19f7+q9atUqV72nv/drVldXl13reV6S\npJ6eqc41Nr1583xP+Xv37s2u9c5Wv+SSS7Jra2p8L0drbp72/G1T8ny9q/XLbU6YAwBAYAQ9AACB\nEfQAAARG0AMAEBhBDwBAYAQ9AACBEfQAAARG0AMAEBhBDwBAYAQ9AACBEfQAAARG0AMAEBhBDwBA\nYAQ9AACBhR1TOzw8rJ07d2bXe0ZBtrS0ZNdKvlGSa9ascfX2jGvdtWuXq/fq1auza/v7+129ly9f\nnl07PDzs6u0Z3+kdS1ymrq4uV71nvO8555zj6u35mh84cMDVu6OjI7vWM15XkhYvXpxde/7557t6\ne7ab53lN8n2PevYVxtQCAIBpEfQAAARG0AMAEBhBDwBAYAQ9AACBEfQAAARG0AMAEBhBDwBAYAQ9\nAACBEfQAAARG0AMAEBhBDwBAYAQ9AACBEfQAAARG0AMAEFjYefRenvnD3lnXntnJra2trt719fXZ\ntd657EuXLs2u9Xy9JOnQoUPZtU888YSrd39/f3bt8ePHXb0988lHR0ddvc8991xX/eDgYHbt5s2b\nXb17enqyaxcsWODqPTY2ll3r/R7dtm1bdq33ucmzrzY1Nbl6e+bC9/X1Zdd6v8fGcUQPAEBgBD0A\nAIER9AAABEbQAwAQGEEPAEBgBD0AAIER9AAABEbQAwAQGEEPAEBgBD0AAIER9AAABEbQAwAQGEEP\nAEBgBD0AAIGFHVNrZq6RqxdccEF27ZVXXpldK0nLly/PrvWOLX3++eeza7u6uly9t2zZkl07f/58\nV+/du3dn13q2mSSNjIxk13r/3579fPHixa7eNTW+44zGxsbs2v3797t6r169urTeBw8ezK7t7Ox0\n9fbUv/nNb3b1bm5uzq71jqldsmRJdu3hw4eza73P5+M4ogcAIDCCHgCAwAh6AAACI+gBAAiMoAcA\nIDCCHgCAwAh6AAACI+gBAAiMoAcAIDCCHgCAwAh6AAACI+gBAAiMoAcAIDCCHgCAwAh6AAACCzuP\nvr6+Xuecc052fU9PT3btoUOHsmslaeXKldm13vnFLS0trnqPvXv3Ztf29va6envmVbe3t7t6e2Z8\nv+Md73D1bm1tza71zGSX/PPo+/r6smsXLVrk6u35mj3zzDOu3p7v8cHBQVdvz3PqzTff7OrtWfvS\npUtdvUdHR7NrDxw4kF3r/R55/XGq8SBmdpuZfd3MnjKzXjNLZnb/FPftKG6f6uOBaqwJAABU74j+\nM5IuldQvabeki06h5kVJD09y/a+qtCYAAOa8agX9x1UJ+NckvUXS46dQ80JKaWOV+gMAgElUJehT\nSq8Hu5lV4yEBAEAVlPlivHYz+7CkVkmHJf08pbSpxPUAABBOmUH/1uLjdWb2E0l3pJR2nsoDmNlz\nU9x0Kq8RAAAgvDLeR39M0hckXSlpafEx/nf96yX92Mx8730BAACSSjiiTykdlPTZE65+0szeJumn\nkq6SdKekr57CY1052fXFkf4VzqUCAHDWmzVnxkspjUr6dvHpdWWuBQCAKGZN0BfGTynHr+4BAKiC\n2Rb0VxeXW0tdBQAAQcx40JvZFWb2e33N7CZVTrwjSZOePhcAAJyeqrwYz8xukXRL8WlbcfknZnZv\n8e/OlNInin//naQLzOxpVc6mJ0mXSLqx+Pc9KaWnq7EuAADmumq96v4ySXeccN364kOSdkgaD/r7\nJL1H0h9JerukOkkHJP2zpG+klJ6q0poAAJjzqnUK3I2SNp7ifb8j6TvV6AsAAE4u7Dz62tpaNTY2\nZtd75nR7Zz5v27Ytu3ZkZMTVe3h4OLt2zZo1rt7Nzc3ZtXv27HH13rnzlE7GOKnt27e7eu/evXv6\nO01h1apVrt7XX399dq1nLrok1dXVuerHxsaya48dO+bq3dHRkV27Y8cOV+/Nmzdn1/b19bl6NzQ0\nZNf29PS4eq9bty671jNPXpK2bNmSXZtScvWuhtn2qnsAAFBFBD0AAIER9AAABEbQAwAQGEEPAEBg\nBD0AAIER9AAABEbQAwAQGEEPAEBgBD0AAIER9AAABEbQAwAQGEEPAEBgBD0AAIGFHVMrSWaWXTs0\nNJRdO3/+/OxayTdC0zuG0jP6s7293dW7trY2u9Y7dtQzMnXfvn2u3itXrsyubWpqcvX27C/ekcht\nbW2u+uXLl2fXXnrppa7enu/xI0eOuHp79tW9e/e6ere0tGTXekcq19TkH5cuW7bM1fuCCy7Irt20\naZOrdzVwRA8AQGAEPQAAgRH0AAAERtADABAYQQ8AQGAEPQAAgRH0AAAERtADABAYQQ8AQGAEPQAA\ngRH0AAAERtADABAYQQ8AQGAEPQAAgRH0AAAEFnYevZlp3rz8/159fX127eWXX55dK1XWnmvPnj2u\n3gcOHMiu9cyLlqT169dn165du9bVe2BgILvWM6Nbkn75y19m146Njbl6Hzp0KLu2trbW1bu1tdVV\nv2HDhuxazyx7SUopZdfeeuutrt6/+MUvsmu3b9/u6r1w4cLsWs8289Z7nxf7+vqyaz055MmCiTii\nBwAgMIIeAIDACHoAAAIj6AEACIygBwAgMIIeAIDACHoAAAIj6AEACIygBwAgMIIeAIDACHoAAAIj\n6AEACIygBwAgMIIeAIDAwo6pHR0dVVdXV3b9qlWrsmuHh4ezayVpZGQku9YzRtJbv3//fldvzxjK\n/v5+V++tW7dm13Z2drp6L1myJLv2tddec/X2jND0jiXevHmzq76pqSm7dtGiRa7enucWL8/32aZN\nm1y9m5ubs2t7enpcvVevXp1d29DQ4OrtGQc9NDSUXXv8+PHs2ok4ogcAIDCCHgCAwAh6AAACI+gB\nAAiMoAcAIDCCHgCAwAh6AAACI+gBAAiMoAcAIDCCHgCAwAh6AAACI+gBAAiMoAcAIDCCHgCAwAh6\nAAACCzuPfmxsTN3d3dn1nlnbHR0d2bVeZuaqr6+vz6596aWXXL3LmvksSfv27cuuXbZsmat3S0tL\ndq1nNrkk1dbWZtf29va6entnund2dmbXXnrppa7ehw8fzq6tq6tz9fbs6319fa7ebW1t2bXLly93\n9W5qasquPe+881y9BwYGsmsfffTR7NpZM4/ezFrN7E4ze8jMXjOzATPrMbOfmtmHzGzSHmZ2jZk9\nYmZdRc0mM7vLzPKfeQAAwO+oxhH97ZK+KWmfpMcl7ZS0UtJ7JX1b0tvN7PaUUhovMLN3S/qepEFJ\n35XUJemdkr4s6driMQEAgFM1gn6LpHdJ+teU0uu/ZzCzv5H0C0m3qhL63yuub5T0j5LGJF2fUnq2\nuP4eSY9Jus3M3pdSeqAKawMAYE5z/+o+pfRYSun7E0O+uH6/pG8Vn14/4abbJC2X9MB4yBf3H5T0\nmeLTj3jXBQAAzvyr7keKy9EJ191YXE72CoUnJR2TdI2ZzT+TCwMAYC44Y6+6N7N5kj5QfDox1C8s\nLrecWJNSGjWzbZL+UNJ6SSd9GbeZPTfFTRed3moBAIjpTB7Rf0nSGyQ9klL6wYTrx98j0TNF3fj1\nzWdqYQAAzBVn5IjezD4m6W5JL0t6/5noIUkppSun6P+cpCvOVF8AAM4WVT+iN7OPSvqqpM2Sbkgp\nnXhWjPEj9qnOfjB+ff7ZbgAAgKQqB72Z3SXp65J+pUrIT3barleKyw2T1M+TtE6VF+9trebaAACY\ni6oW9Gb2KVVOePOCKiF/cIq7PlZc3jzJbddJWijp6ZSS75ymAACgOkFfnOzmS5Kek3RTSulkJ6F+\nUFKnpPeZ2ZsmPEaDpC8Wn36zGusCAGCuc78Yz8zukPR5Vc5095Skj00yWGV7SuleSUop9ZrZn6sS\n+D8xswdUOQXuu1R5692DqpwWFwAAOFXjVffristaSXdNcZ8nJN07/klK6WEze4ukT6tyitwGSa9J\n+mtJX5t4XnwAAJDPHfQppY2SNmbU/UzSn3r7T2VsbMw1RtMzrnXPnj3ZtZJvNOGSJUtcvT2jQxsa\nGly9h4eHs2u9Y2p3795dWu+enqlOKTG9zZs3u3p7Rof29/e7enu/TzzjfT0jkSXfiN7LLrvM1dsz\n5vbyyy939V68eHEptd76+fN9J1o9cuRIdq3nOdkzRnqiM30KXAAAUCKCHgCAwAh6AAACI+gBAAiM\noAcAIDCCHgCAwAh6AAACI+gBAAiMoAcAIDCCHgCAwAh6AAACI+gBAAiMoAcAIDCCHgCAwAh6AAAC\nc8+jn61GRka0b9++7HrPjPCdO3dm10q+GeEXXXSRq7dnbnNjY6Ort+frNTIy4urtma3umTctSYOD\ng9m1ntnkkm/etWc/laTzzz/fVX/06FFXvceBAweya3/0ox+5end3d2fXDg0NuXovXbo0u3b9+vWu\n3p2dndm1fX19rt7Dw8PZtZ5Z9qOjo9m1E3FEDwBAYAQ9AACBEfQAAARG0AMAEBhBDwBAYAQ9AACB\nEfQAAARG0AMAEBhBDwBAYAQ9AACBEfQAAARG0AMAEBhBDwBAYAQ9AACBhR1TW1dXp/b29uz6hoaG\n7FrvOEbPGMoyR6YuW7bM1dvz9fKMFZZ8azczV2/P19szZlaSmpubs2uPHTvm6t3W1uaqb2lpya71\njmu96qqrsms941YlaevWraX19tR7xxL39vZm13q/3k1NTdm1nhHaKaXs2ok4ogcAIDCCHgCAwAh6\nAAACI+gBAAiMoAcAIDCCHgCAwAh6AAACI+gBAAiMoAcAIDCCHgCAwAh6AAACI+gBAAiMoAcAIDCC\nHgCAwAh6AAACCzuPXpLGxsaya/fs2ZNd650JP3/+/OzaXbt2uXp7tllHR4erd11dXXbtqlWrXL09\n9u3b56pfvHhxdq13X/PMyvZ+vT3z5CVpeHg4u/bAgQOu3maWXev9HvVobm521e/YsSO71jPLXpIO\nHjyYXeud697a2ppdW19fn13r2c8m4ogeAIDACHoAAAIj6AEACIygBwAgMIIeAIDACHoAAAIj6AEA\nCIygBwAgMIIeAIDACHoAAAIj6AEACIygBwAgMIIeAIDACHoAAAILO6bWzNTQ0JBdX1OT/zPQwMBA\ndq3kG1Pb1NTk6t3f359du3v3bldvj5UrV7rqh4aGsmuXLVvm6u0Zoblw4UJX76NHj2bXevZTyT8q\n1sMzjlnyjWv1jC2VfGv3jmtdu3Ztdq13mx87diy71pMFkrR///7s2nnzyo9Z9xG9mbWa2Z1m9pCZ\nvWZmA2bWY2Y/NbMPmVnNCffvMLN0ko8HvGsCAAAV1fhR43ZJ35S0T9LjknZKWinpvZK+LentZnZ7\n+v0fJV+U9PAkj/erKqwJAACoOkG/RdK7JP1rSun4+JVm9jeSfiHpVlVC/3sn1L2QUtpYhf4AAGAK\n7l/dp5QeSyl9f2LIF9fvl/St4tPrvX0AAMDpO9OvEhgpLkcnua3dzD4sqVXSYUk/TyltOsPrAQBg\nTjljQW9m8yR9oPj00Unu8tbiY2LNTyTdkVLaeabWBQDAXHImj+i/JOkNkh5JKf1gwvXHJH1BlRfi\nbS2uu0TSRkk3SPqxmV2WUpr2fT9m9twUN12Uu2gAACI5IyfMMbOPSbpb0suS3j/xtpTSwZTSZ1NK\nz6eUuouPJyW9TdK/Szpf0p1nYl0AAMw1VT+iN7OPSvqqpM2SbkopdZ1KXUpp1My+LekqSdcVjzFd\nzZVTrOE5SVec8qIBAAiqqkf0ZnaXpK+r8l74G4pX3p+OQ8XlomquCwCAuapqQW9mn5L0ZUkvqBLy\nBzMe5uricutJ7wUAAE5JVYLezO5R5cV3z6ny6/rOk9z3ihNPi1tcf5Okjxef3l+NdQEAMNe5/0Zv\nZndI+rykMUlPSfqYmZ14t+0ppXuLf/+dpAvM7GlJ41NQLpF0Y/Hve1JKT3vXBQAAqvNivHXFZa2k\nu6a4zxOS7i3+fZ+k90j6I0lvl1Qn6YCkf5b0jZTSU1VYEwAAUBWCvjhf/cbTuP93JH3H2xcAAEyv\n/EG5Z0jMhgSfAAAImklEQVR9fb3OPffc7Pq2trbsWu/s46VLl2bX9vX1uXp7eOcuNzU1Zdd6Z10v\nWLAgu9Y7E/7IkSPZtY2Nja7eHsPDw676np4eV/0kfyI8ZYsW+d7Y4/maLV682NXb8/zieW6RpObm\n5uzawcFBV2/P8/nIyMj0dzqJvXv3ZtcuWbIku7ampjqvlz8jJ8wBAACzA0EPAEBgBD0AAIER9AAA\nBEbQAwAQGEEPAEBgBD0AAIER9AAABEbQAwAQGEEPAEBgBD0AAIER9AAABEbQAwAQGEEPAEBgYcfU\njo2NucZg1tbWZtceP348u1byjUz1jor1jLH0jv7ctm1bdm1dXZ2rt2eb79u3z9Xbs807OztdvT3f\nI/Pnz3f1rq+vd9V7xn96RtxKvpGrXV1drt6eMbfeUbGeca3er7en3vv80N7enl3ryQPvfjqOI3oA\nAAIj6AEACIygBwAgMIIeAIDACHoAAAIj6AEACIygBwAgMIIeAIDACHoAAAIj6AEACIygBwAgMIIe\nAIDACHoAAAIj6AEACMxSSmWvoerM7HBtbW2LZ/ynZzygd7SgZ0Sul6d3TY3v58ahoaHsWu8296x9\nbGzM1bvMkcietXu/3t7nnjK/Tzzbzfs18/y/vd8nnrV795cyn5M9+6qntrOzU6Ojo10ppdbsB1Hc\nefS9Y2Nj6uzs3D7F7RcVly/P0HoiYJvlYbvlYbudPrZZntm83Tok9XofJOQR/XTM7DlJSildWfZa\nzhZsszxstzxst9PHNsszF7Ybf6MHACAwgh4AgMAIegAAAiPoAQAIjKAHACCwOfmqewAA5gqO6AEA\nCIygBwAgMIIeAIDACHoAAAIj6AEACIygBwAgMIIeAIDA5lTQm9k5Zva/zGyvmQ2Z2XYz+4qZ5Q+u\nD67YRmmKj/1lr68sZnabmX3dzJ4ys95ie9w/Tc01ZvaImXWZ2YCZbTKzu8ysvMHqM+x0tpuZdZxk\n30tm9sBMr78MZtZqZnea2UNm9lqx7/SY2U/N7ENmNunz+Fzf3053u0Xe36LOo/89ZnaepKclrZD0\nL6rMHv5jSX8l6WYzuzaldLjEJc5mPZK+Msn1/TO9kFnkM5IuVWUb7NZvZ1pPyszeLel7kgYlfVdS\nl6R3SvqypGsl3X4mFzuLnNZ2K7wo6eFJrv9VFdc1m90u6ZuS9kl6XNJOSSslvVfStyW93cxuTxPO\nfsb+JiljuxXi7W8ppTnxIekHkpKk/3LC9X9XXP+tstc4Gz8kbZe0vex1zLYPSTdIukCSSbq+2Ifu\nn+K+jZIOShqS9KYJ1zeo8sNnkvS+sv9Ps3C7dRS331v2ukveZjeqEtI1J1zfpkp4JUm3Trie/S1v\nu4Xd3+bEr+6Lo/m3qRJaf3/CzX8r6aik95vZohleGs5SKaXHU0qvpuIZYhq3SVou6YGU0rMTHmNQ\nlSNcSfrIGVjmrHOa2w2SUkqPpZS+n1I6fsL1+yV9q/j0+gk3sb8pa7uFNVd+dX9DcfnDSb7ofWb2\nM1V+ELha0o9nenFngflm9meSzlXlh6JNkp5MKY2Vu6yzxo3F5aOT3PakpGOSrjGz+SmloZlb1lmj\n3cw+LKlV0mFJP08pbSp5TbPFSHE5OuE69rfpTbbdxoXb3+ZK0F9YXG6Z4vZXVQn6DSLoJ9Mm6b4T\nrttmZh9MKT1RxoLOMlPufymlUTPbJukPJa2X9NJMLuws8dbi43Vm9hNJd6SUdpayolnAzOZJ+kDx\n6cRQZ387iZNst3Hh9rc58at7SU3FZc8Ut49f3zwDaznb/JOkm1QJ+0WS3ijpH1T5e9a/mdml5S3t\nrMH+l+eYpC9IulLS0uLjLaq8sOp6ST+e439u+5KkN0h6JKX0gwnXs7+d3FTbLez+NleCHplSSp8r\n/tZ1IKV0LKX0q5TSX6jyIsYFkjaWu0JElVI6mFL6bErp+ZRSd/HxpCq/fft3SedLurPcVZbDzD4m\n6W5V3j30/pKXc9Y42XaLvL/NlaAf/wm2aYrbx6/vnoG1RDH+YpbrSl3F2YH9r4pSSqOqvD1KmoP7\nn5l9VNJXJW2WdENKqeuEu7C/TeIUttukIuxvcyXoXykuN0xx+wXF5VR/w8fvO1RcnpW/ypphU+5/\nxd8L16nyoqCtM7mos9yc3P/M7C5JX1flPd03FK8gPxH72wlOcbudzFm9v82VoH+8uHzbJGdDWqLK\nCSSOSXpmphd2Fru6uJwzTxYOjxWXN09y23WSFkp6eg6/AjrHnNv/zOxTqpzw5gVVwurgFHdlf5vg\nNLbbyZzV+9ucCPqU0m8k/VCVF5D95Qk3f06Vn9LuSykdneGlzWpm9geTvfjEzDokfaP49KSnfYUk\n6UFJnZLeZ2ZvGr/SzBokfbH49JtlLGw2M7MrJju9q5ndJOnjxadzYv8zs3tUeRHZc5JuSil1nuTu\n7G+F09lukfc3myvnrZjkFLgvSbpKlffYb5F0TeIUuL/DzDaq8sKVJyXtkNQn6TxJ71DlLFuPSHpP\nSmm4rDWWxcxukXRL8WmbpP+gyk/7TxXXdaaUPnHC/R9U5ZSkD6hyStJ3qfJWqAcl/ce5cBKZ09lu\nxVuaLlDl+3Z3cfsl+u37xO9JKY0HV1hmdoekeyWNqfLr58leTb89pXTvhJo5v7+d7nYLvb+VfWq+\nmfyQtEaVt4vtkzSsSnh9RdLSstc2Gz9UeWvJ/1blFardqpxk4pCk/6vK+1Ct7DWWuG02qnK6zKk+\ntk9Sc60qPxwdkTQg6f+pcqRQW/b/ZzZuN0kfkvR/VDmjZb8qp3Tdqcq5299c9v9lFm2zJOkn7G++\n7RZ5f5szR/QAAMxFc+Jv9AAAzFUEPQAAgRH0AAAERtADABAYQQ8AQGAEPQAAgRH0AAAERtADABAY\nQQ8AQGAEPQAAgRH0AAAERtADABAYQQ8AQGAEPQAAgRH0AAAERtADABAYQQ8AQGD/H7GFySs2LpeM\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f70c3eff7b8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try generating image\n",
    "\n",
    "z = np.random.randn(100).reshape(1, 100)\n",
    "img = G.predict([z, np.array([8])])\n",
    "plt.imshow(img.reshape((28, 28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get our mnist data, and force it to be of shape (..., 28, 28, 1) with\n",
    "# range [-1., 1.]\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "X_test = np.expand_dims(X_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f70c045ff28>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRjEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f70c3eff668>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[777].reshape((28, 28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num_samples, test_num_samples = X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_history = defaultdict(list)\n",
    "test_history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_generated_samples(epoch, G):\n",
    "\n",
    "    # new batch of z's\n",
    "    zz = np.random.normal(0., 1., (100, Z_SIZE))\n",
    "\n",
    "    # new batch of classes [0..9]\n",
    "    generated_classes = np.random.randint(0, 10, 100)\n",
    "\n",
    "    generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "    rr = []\n",
    "    for c in range(10):\n",
    "        rr.append(np.concatenate(generated_images[c * 10:(1 + c) * 10]).reshape(280, 28))\n",
    "    img = np.hstack(rr)\n",
    "\n",
    "    plt.imsave('out/generated-e%d.png'%epoch, img, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 1.9720 - D(G)_loss: 1.8402\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[1.3356032371520996, 0.007638853974640369, 1.3279653787612915]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[0.9179622530937195, -0.2889561355113983, 1.206918716430664]\n",
      "\n",
      "Epoch 2 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.3152 - D(G)_loss: -1.0165\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.2880123555660248, 0.023960107937455177, 0.26405221223831177]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.0416392087936401, -1.0794730186462402, 0.03783345967531204]\n",
      "\n",
      "Epoch 3 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.2399 - D(G)_loss: -1.2110\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.22430138289928436, 0.023195965215563774, 0.20110547542572021]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.218503475189209, -1.2397440671920776, 0.021240422502160072]\n",
      "\n",
      "Epoch 4 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.1958 - D(G)_loss: -1.2517\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.1867613047361374, 0.019999880343675613, 0.16676142811775208]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.2731536626815796, -1.2904108762741089, 0.01725725643336773]\n",
      "\n",
      "Epoch 5 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.1689 - D(G)_loss: -1.3043\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.16076840460300446, 0.01958932727575302, 0.1411791294813156]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.3258984088897705, -1.3409169912338257, 0.01501945499330759]\n",
      "\n",
      "Epoch 6 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.1475 - D(G)_loss: -1.4103\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.13994327187538147, 0.020283866673707962, 0.11965931951999664]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.3576927185058594, -1.3713525533676147, 0.01365889422595501]\n",
      "\n",
      "Epoch 7 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.1287 - D(G)_loss: -1.2294\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.12270717322826385, 0.020060664042830467, 0.10264641791582108]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.2568901777267456, -1.269974708557129, 0.013084771111607552]\n",
      "\n",
      "Epoch 8 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.1152 - D(G)_loss: -1.3333\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.10981830954551697, 0.019264454022049904, 0.09055383503437042]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.3654268980026245, -1.3773040771484375, 0.011877010576426983]\n",
      "\n",
      "Epoch 9 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.1096 - D(G)_loss: -1.3467\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.10430358350276947, 0.01953403651714325, 0.08476956933736801]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.3657160997390747, -1.3776756525039673, 0.011959490366280079]\n",
      "\n",
      "Epoch 10 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0977 - D(G)_loss: -1.3778\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.0954807922244072, 0.018186956644058228, 0.07729378342628479]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.386655330657959, -1.3981508016586304, 0.011496287770569324]\n",
      "\n",
      "Epoch 11 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0914 - D(G)_loss: -1.4792\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.09184587001800537, 0.019353587180376053, 0.07249227166175842]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.46959388256073, -1.480368971824646, 0.010775359347462654]\n",
      "\n",
      "Epoch 12 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0891 - D(G)_loss: -1.4605\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.08809815347194672, 0.020233137533068657, 0.06786509603261948]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.4287556409835815, -1.439081072807312, 0.010325048118829727]\n",
      "\n",
      "Epoch 13 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0831 - D(G)_loss: -1.4343\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.08158709108829498, 0.016689077019691467, 0.06489799171686172]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.4531822204589844, -1.4627224206924438, 0.009540306404232979]\n",
      "\n",
      "Epoch 14 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0814 - D(G)_loss: -1.4690\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.07992954552173615, 0.017010554671287537, 0.0629190132021904]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.516594409942627, -1.5265971422195435, 0.010002842172980309]\n",
      "\n",
      "Epoch 15 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0781 - D(G)_loss: -1.5728\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.07667329907417297, 0.016485638916492462, 0.06018770858645439]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.5686777830123901, -1.5788508653640747, 0.010172927752137184]\n",
      "\n",
      "Epoch 16 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0734 - D(G)_loss: -1.6315\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.07438410073518753, 0.017000440508127213, 0.057383663952350616]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.6491020917892456, -1.6593009233474731, 0.01019793190062046]\n",
      "\n",
      "Epoch 17 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0736 - D(G)_loss: -1.7571\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.07309085130691528, 0.0164369847625494, 0.05665384978055954]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.8055583238601685, -1.8153882026672363, 0.009830097667872906]\n",
      "\n",
      "Epoch 18 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0711 - D(G)_loss: -1.8715\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.07068371772766113, 0.016133004799485207, 0.05455074459314346]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.8857293128967285, -1.8952325582504272, 0.009504415094852448]\n",
      "\n",
      "Epoch 19 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0681 - D(G)_loss: -1.9648\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.06667547672986984, 0.013596786186099052, 0.05307867377996445]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-1.9759098291397095, -1.9851497411727905, 0.009239145554602146]\n",
      "\n",
      "Epoch 20 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0669 - D(G)_loss: -2.0347\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.06768214702606201, 0.015135184861719608, 0.05254693329334259]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.0800368785858154, -2.0918116569519043, 0.01177461352199316]\n",
      "\n",
      "Epoch 21 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0702 - D(G)_loss: -2.1132\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.06764300167560577, 0.01584981195628643, 0.05179320275783539]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.12375807762146, -2.133957862854004, 0.010201691649854183]\n",
      "\n",
      "Epoch 22 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0662 - D(G)_loss: -2.1315\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.06595032662153244, 0.015988605096936226, 0.04996174946427345]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.159912109375, -2.169179916381836, 0.009267241694033146]\n",
      "\n",
      "Epoch 23 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0666 - D(G)_loss: -2.1307\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.06367209553718567, 0.015218585729598999, 0.04845351353287697]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.146796703338623, -2.1562745571136475, 0.009477149695158005]\n",
      "\n",
      "Epoch 24 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0620 - D(G)_loss: -2.2299\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.06135354936122894, 0.013421223498880863, 0.047932278364896774]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.2798333168029785, -2.2905311584472656, 0.01070030964910984]\n",
      "\n",
      "Epoch 25 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0636 - D(G)_loss: -2.3426\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.06315354257822037, 0.017233632504940033, 0.04591985046863556]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.3627045154571533, -2.371398687362671, 0.008693012408912182]\n",
      "\n",
      "Epoch 26 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0622 - D(G)_loss: -2.4380\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.06356770545244217, 0.0170269925147295, 0.04654063284397125]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.488028049468994, -2.4978787899017334, 0.009850352071225643]\n",
      "\n",
      "Epoch 27 / 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0609 - D(G)_loss: -2.4566\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.0619531013071537, 0.016864852979779243, 0.045088231563568115]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.443985939025879, -2.453509569168091, 0.009524858556687832]\n",
      "\n",
      "Epoch 28 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0573 - D(G)_loss: -2.4607\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.05969258025288582, 0.01478531677275896, 0.04490732029080391]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.51486873626709, -2.524232864379883, 0.009363073855638504]\n",
      "\n",
      "Epoch 29 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0594 - D(G)_loss: -2.6470\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.057449664920568466, 0.013112282380461693, 0.044337399303913116]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.6576998233795166, -2.6670069694519043, 0.009309175424277782]\n",
      "\n",
      "Epoch 30 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0584 - D(G)_loss: -2.6717\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.05624009296298027, 0.01442082691937685, 0.0418192483484745]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.71471905708313, -2.723097085952759, 0.008378819562494755]\n",
      "\n",
      "Epoch 31 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0563 - D(G)_loss: -2.8624\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.05705350264906883, 0.015220877714455128, 0.04183260723948479]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-2.9307634830474854, -2.9398069381713867, 0.009043669328093529]\n",
      "\n",
      "Epoch 32 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0574 - D(G)_loss: -3.0207\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.05688295513391495, 0.01499110832810402, 0.04189183935523033]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.0280637741088867, -3.037067413330078, 0.009004704654216766]\n",
      "\n",
      "Epoch 33 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0574 - D(G)_loss: -3.0087\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.055892735719680786, 0.014938322827219963, 0.04095440357923508]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.0751280784606934, -3.083535671234131, 0.008406668901443481]\n",
      "\n",
      "Epoch 34 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0582 - D(G)_loss: -3.0481\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.05833440274000168, 0.01758158579468727, 0.0407528318464756]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.0798680782318115, -3.08856201171875, 0.008693702518939972]\n",
      "\n",
      "Epoch 35 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0575 - D(G)_loss: -3.0018\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.05587682127952576, 0.015746768563985825, 0.04013004153966904]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.016136407852173, -3.0253450870513916, 0.009206480346620083]\n",
      "\n",
      "Epoch 36 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0565 - D(G)_loss: -3.0412\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.05605965480208397, 0.01663488894701004, 0.03942475467920303]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.0623512268066406, -3.0700502395629883, 0.007699755951762199]\n",
      "\n",
      "Epoch 37 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0529 - D(G)_loss: -2.9796\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.05146543309092522, 0.012477460317313671, 0.03898797929286957]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.00295090675354, -3.01118540763855, 0.008233791217207909]\n",
      "\n",
      "Epoch 38 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0531 - D(G)_loss: -3.1071\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.052059609442949295, 0.013584976084530354, 0.03847462311387062]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.119549036026001, -3.1279759407043457, 0.008427769877016544]\n",
      "\n",
      "Epoch 39 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0502 - D(G)_loss: -3.1140\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.05100765824317932, 0.01271091029047966, 0.03829680010676384]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.10396409034729, -3.1124980449676514, 0.008530896157026291]\n",
      "\n",
      "Epoch 40 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0527 - D(G)_loss: -3.1437\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.05322198197245598, 0.015401358716189861, 0.03782065957784653]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.1296803951263428, -3.1378817558288574, 0.008203535340726376]\n",
      "\n",
      "Epoch 41 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0526 - D(G)_loss: -3.1481\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.051578886806964874, 0.014135509729385376, 0.03744342550635338]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.2027649879455566, -3.211069345474243, 0.008305923081934452]\n",
      "\n",
      "Epoch 42 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0514 - D(G)_loss: -3.2513\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.051287077367305756, 0.014488899149000645, 0.036798205226659775]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.280719757080078, -3.2887611389160156, 0.008038794621825218]\n",
      "\n",
      "Epoch 43 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0496 - D(G)_loss: -3.2310\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.048961542546749115, 0.013029112480580807, 0.03593243286013603]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.2877986431121826, -3.2958436012268066, 0.00804508849978447]\n",
      "\n",
      "Epoch 44 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0520 - D(G)_loss: -3.4261\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.05095502734184265, 0.014149114489555359, 0.0368058979511261]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.4608051776885986, -3.468874216079712, 0.008069640956819057]\n",
      "\n",
      "Epoch 45 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0517 - D(G)_loss: -3.3754\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.051759395748376846, 0.016147727146744728, 0.03561168909072876]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.3954293727874756, -3.403264045715332, 0.007836973294615746]\n",
      "\n",
      "Epoch 46 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0519 - D(G)_loss: -3.3346\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.04921060428023338, 0.013645585626363754, 0.03556499630212784]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.386596202850342, -3.3951468467712402, 0.008550429716706276]\n",
      "\n",
      "Epoch 47 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0468 - D(G)_loss: -3.4963\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.04688416048884392, 0.011419338174164295, 0.035464853048324585]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.538571834564209, -3.5463900566101074, 0.007819545455276966]\n",
      "\n",
      "Epoch 48 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0460 - D(G)_loss: -3.7335\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.04907669126987457, 0.01364392414689064, 0.035432808101177216]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.707338809967041, -3.716214656829834, 0.008876374922692776]\n",
      "\n",
      "Epoch 49 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0555 - D(G)_loss: -3.5714\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.052722323685884476, 0.017470773309469223, 0.03525157645344734]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.5629751682281494, -3.571211814880371, 0.008237234316766262]\n",
      "\n",
      "Epoch 50 / 50\n",
      "599/600 [============================>.] - ETA: 0s - D_loss: 0.0467 - D(G)_loss: -3.4774\n",
      "D: ['loss', 'output_is_fake_loss', 'output_class_loss']\n",
      "[0.04741813614964485, 0.012799958698451519, 0.03461819514632225]\n",
      "D(G): ['loss', 'D_loss', 'D_loss']\n",
      "[-3.5012781620025635, -3.5096683502197266, 0.008389460854232311]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print('\\nEpoch {} / {}'.format(epoch + 1, EPOCHS))\n",
    "\n",
    "    batches_num = int(train_num_samples / BATCH_SIZE)\n",
    "    progress_bar = Progbar(target=batches_num)\n",
    "\n",
    "    epoch_combined_losses = []\n",
    "    epoch_D_losses = []\n",
    "\n",
    "    for batch_i in range(batches_num):\n",
    "\n",
    "        if len(epoch_D_losses) + len(epoch_combined_losses) > 1:\n",
    "            progress_bar.update(\n",
    "                batch_i,\n",
    "                values=[\n",
    "                        ('D_loss', np.mean(np.array(epoch_D_losses), axis=0)[0]),\n",
    "                        ('D(G)_loss', np.mean(np.array(epoch_combined_losses),axis=0)[0])\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            progress_bar.update(batch_i)\n",
    "            \n",
    "        # 1: train D on real+generated images\n",
    "            \n",
    "        # create batches of images and labels\n",
    "        real_images = X_train[batch_i * BATCH_SIZE:(batch_i + 1) * BATCH_SIZE]\n",
    "        real_images_classes = y_train[batch_i * BATCH_SIZE:(batch_i + 1) * BATCH_SIZE]\n",
    "        \n",
    "        # new batch of z's\n",
    "        zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE))\n",
    "        \n",
    "        # new batch of classes [0..9]\n",
    "        generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "        \n",
    "        generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "        \n",
    "        X = np.concatenate((real_images, generated_images))\n",
    "        y_is_fake = np.array([-1] * BATCH_SIZE + [1] * BATCH_SIZE) # [is_fake=-1xBATCH_SIZE, 1xBATCH_SIZE]\n",
    "        y_classes = np.concatenate((real_images_classes, generated_classes))\n",
    "        \n",
    "        # train \n",
    "        D_losses = D.train_on_batch(X, [y_is_fake, y_classes])\n",
    "        epoch_D_losses.append(D_losses)\n",
    "        \n",
    "        \n",
    "        # 2: train D(G) (only G is trainable)\n",
    "        \n",
    "        # 2x so G is trained for the same number of images\n",
    "        # as D above (which is trained on real+generated)\n",
    "        zz = np.random.normal(0., 1., (2 * BATCH_SIZE, Z_SIZE)) \n",
    "        generated_classes = np.random.randint(0, 10, 2 * BATCH_SIZE)\n",
    "\n",
    "        y_is_fake = -np.ones(2 * BATCH_SIZE) # all not-fake\n",
    "\n",
    "        combined_losses = combined.train_on_batch(\n",
    "            [zz, generated_classes.reshape((-1, 1))],\n",
    "            [y_is_fake, generated_classes])\n",
    "        \n",
    "        epoch_combined_losses.append(combined_losses)\n",
    "        \n",
    "    print('\\nD:', D.metrics_names)\n",
    "    print(np.mean(np.array(epoch_D_losses), axis=0).tolist())\n",
    "    \n",
    "    print('D(G):', combined.metrics_names)\n",
    "    print(np.mean(np.array(epoch_combined_losses), axis=0).tolist())\n",
    "    \n",
    "    save_generated_samples(epoch, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Keras  WACGAN",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
