{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils.generic_utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND = 777\n",
    "\n",
    "RUN = 'A'\n",
    "OUT_DIR = 'out/' + RUN\n",
    "TENSORBOARD_DIR = '/tensorboard/wgans/' + RUN\n",
    "\n",
    "# GPU # \n",
    "GPU = \"0\"\n",
    "\n",
    "# latent vector size\n",
    "Z_SIZE = 100\n",
    "\n",
    "# number of iterations D is trained for per each G iteration\n",
    "D_ITERS = 5\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "ITERATIONS = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(OUT_DIR): os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use specific GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basically return mean(y_pred),\n",
    "# but with ability to inverse it for minimization (when y_true == -1)\n",
    "def wasserstein(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_D():\n",
    "\n",
    "    # weights are initlaized from normal distribution with below params\n",
    "    weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "    input_image = Input(shape=(28, 28, 1), name='input_image')\n",
    "\n",
    "    x = Conv2D(\n",
    "        32, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_1',\n",
    "        kernel_initializer=weight_init)(input_image)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        64, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_2',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        128, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_3',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        256, (3, 3),\n",
    "        padding='same',\n",
    "        name='coonv_4',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    features = Flatten()(x)\n",
    "\n",
    "    output_is_fake = Dense(\n",
    "        1, activation='linear', name='output_is_fake')(features)\n",
    "\n",
    "    output_class = Dense(\n",
    "        10, activation='softmax', name='output_class')(features)\n",
    "\n",
    "    return Model(\n",
    "        inputs=[input_image], outputs=[output_is_fake, output_class], name='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_G(Z_SIZE=Z_SIZE):\n",
    "    DICT_LEN = 10\n",
    "    EMBEDDING_LEN = Z_SIZE\n",
    "\n",
    "    # weights are initlaized from normal distribution with below params\n",
    "    weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "    # class#\n",
    "    input_class = Input(shape=(1, ), dtype='int32', name='input_class')\n",
    "    # encode class# to the same size as Z to use hadamard multiplication later on\n",
    "    e = Embedding(\n",
    "        DICT_LEN, EMBEDDING_LEN,\n",
    "        embeddings_initializer='glorot_uniform')(input_class)\n",
    "    embedded_class = Flatten(name='embedded_class')(e)\n",
    "\n",
    "    # latent var\n",
    "    input_z = Input(shape=(Z_SIZE, ), name='input_z')\n",
    "\n",
    "    # hadamard product\n",
    "    h = multiply([input_z, embedded_class], name='h')\n",
    "\n",
    "    # cnn part\n",
    "    x = Dense(1024)(h)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Dense(128 * 7 * 7)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Reshape((7, 7, 128))(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, (5, 5), padding='same', kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, (5, 5), padding='same', kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        1, (2, 2),\n",
    "        padding='same',\n",
    "        activation='tanh',\n",
    "        name='output_generated_image',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "\n",
    "    return Model(inputs=[input_z, input_class], outputs=x, name='G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "\n",
    "D = create_D()\n",
    "\n",
    "D.compile(\n",
    "    optimizer=RMSprop(lr=0.00005),\n",
    "    loss=[wasserstein, 'sparse_categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_z = Input(shape=(Z_SIZE, ), name='input_z_')\n",
    "input_class = Input(shape=(1, ),name='input_class_', dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "\n",
    "G = create_G()\n",
    "\n",
    "# create combined D(G) model\n",
    "# D.trainable = False\n",
    "output_is_fake, output_class = D(G(inputs=[input_z, input_class]))\n",
    "DG = Model(inputs=[input_z, input_class], outputs=[output_is_fake, output_class])\n",
    "DG.get_layer('D').trainable = False # freeze D in generator training faze\n",
    "\n",
    "DG.compile(\n",
    "    optimizer=RMSprop(lr=0.00005),\n",
    "    loss=[wasserstein, 'sparse_categorical_crossentropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc53412ce80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPQAAgRH0AAAE9v8BQ/+iQb4BZrgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc53848ee48>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try generating image\n",
    "z = np.random.randn(100).reshape(1, 100)\n",
    "img = G.predict([z, np.array([8])])\n",
    "plt.imshow(img.reshape((28, 28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get our mnist data, and force it to be of shape (..., 28, 28, 1) with\n",
    "# range [-1., 1.]\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "X_test = np.expand_dims(X_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num_samples, test_num_samples = X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write TensorBoard summaries\n",
    "\n",
    "sw = tf.summary.FileWriter(TENSORBOARD_DIR)\n",
    "\n",
    "\n",
    "def update_tb_summary(step):\n",
    "\n",
    "    s = tf.Summary()\n",
    "\n",
    "    # losses as is\n",
    "    for names, vals in zip((('D_true_is_fake', 'D_true_class'),\n",
    "                            ('D_fake_is_fake', 'D_fake_class'), ('DG_is_fake',\n",
    "                                                                 'DG_class')),\n",
    "                           (D_true_losses, D_fake_losses, DG_losses)):\n",
    "\n",
    "        v1 = s.value.add()\n",
    "        v1.simple_value = vals[-1][1]\n",
    "        v1.tag = names[0]\n",
    "\n",
    "        v1 = s.value.add()\n",
    "        v1.simple_value = vals[-1][2]\n",
    "        v1.tag = names[1]\n",
    "\n",
    "    # D loss: -1*D_true_is_fake - D_fake_is_fake\n",
    "    v = s.value.add()\n",
    "    v.simple_value = -D_true_losses[-1][1] - D_fake_losses[-1][1]\n",
    "    v.tag = 'D loss (-1*D_true_is_fake - D_fake_is_fake)'\n",
    "\n",
    "    # image\n",
    "\n",
    "    img = generate_samples(save=False)\n",
    "    s.MergeFromString(tf.Session().run(\n",
    "        tf.summary.image('generated_samples',\n",
    "            img.reshape([1, *img.shape, 1]))))\n",
    "\n",
    "    sw.add_summary(s, step)\n",
    "    sw.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save 10x10 sample of generated images\n",
    "def generate_samples(n=0, save=True):\n",
    "    \n",
    "    zz = np.random.normal(0., 1., (100, Z_SIZE))\n",
    "    generated_classes = np.array(list(range(0, 10)) * 10)\n",
    "    generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "    rr = []\n",
    "    for c in range(10):\n",
    "        rr.append(\n",
    "            np.concatenate(generated_images[c * 10:(1 + c) * 10]).reshape(\n",
    "                280, 28))\n",
    "    img = np.hstack(rr)\n",
    "\n",
    "    if save:\n",
    "        plt.imsave(OUT_DIR + '/generated@%d.png' % n, img, cmap=plt.cm.gray)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13/1000000 [..............................] - ETA: 5846901s - D_real_is_fake: -507.6297 - D_real_class: 3.7912 - D_fake_is_fake: 305.4817 - D_fake_class: 3.8160 - D(G)_is_fake: -228.3584 - D(G)_class: 3.2712"
     ]
    }
   ],
   "source": [
    "# fake = 1\n",
    "# real = -1\n",
    "\n",
    "progress_bar = Progbar(target=ITERATIONS)\n",
    "\n",
    "DG_losses = []\n",
    "D_true_losses = []\n",
    "D_fake_losses = []\n",
    "\n",
    "for it in range(ITERATIONS):\n",
    "\n",
    "    if len(D_true_losses) > 0:\n",
    "        progress_bar.update(\n",
    "            it,\n",
    "            values=[\n",
    "                    ('D_real_is_fake', np.mean(D_true_losses[-5:], axis=0)[1]),\n",
    "                    ('D_real_class', np.mean(D_true_losses[-5:], axis=0)[2]),\n",
    "                    ('D_fake_is_fake', np.mean(D_fake_losses[-5:], axis=0)[1]),\n",
    "                    ('D_fake_class', np.mean(D_fake_losses[-5:], axis=0)[2]),\n",
    "                    ('D(G)_is_fake', np.mean(DG_losses[-5:],axis=0)[1]),\n",
    "                    ('D(G)_class', np.mean(DG_losses[-5:],axis=0)[2])\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        progress_bar.update(it)\n",
    "\n",
    "    # 1: train D on real+generated images\n",
    "\n",
    "    if it < 25 or it % 500 == 0:\n",
    "        d_iters = 100\n",
    "    else:\n",
    "        d_iters = D_ITERS\n",
    "\n",
    "    for d_it in range(d_iters):\n",
    "\n",
    "        # unfreeze D\n",
    "        D.trainable = True\n",
    "        for l in D.layers: l.trainable = True\n",
    "\n",
    "        # clip D weights\n",
    "\n",
    "        for l in D.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "\n",
    "        # 1.1: maximize D output on reals === minimize -1*(D(real))\n",
    "\n",
    "        # draw random samples from real images\n",
    "        index = np.random.choice(train_num_samples, BATCH_SIZE, replace=False)\n",
    "        real_images = X_train[index]\n",
    "        real_images_classes = y_train[index]\n",
    "\n",
    "        D_loss = D.train_on_batch(real_images, [-np.ones(BATCH_SIZE), real_images_classes])\n",
    "        D_true_losses.append(D_loss)\n",
    "\n",
    "        # 1.2: minimize D output on fakes \n",
    "\n",
    "        zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE))\n",
    "        generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "        generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "        D_loss = D.train_on_batch(generated_images, [np.ones(BATCH_SIZE), generated_classes])\n",
    "        D_fake_losses.append(D_loss)\n",
    "\n",
    "    # 2: train D(G) (D is frozen)\n",
    "    # minimize D output while supplying it with fakes, telling it that they are reals (-1)\n",
    "\n",
    "    # freeze D\n",
    "    D.trainable = False\n",
    "    for l in D.layers: l.trainable = False\n",
    "\n",
    "    zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE)) \n",
    "    generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "\n",
    "    DG_loss = DG.train_on_batch(\n",
    "        [zz, generated_classes.reshape((-1, 1))],\n",
    "        [-np.ones(BATCH_SIZE), generated_classes])\n",
    "\n",
    "    DG_losses.append(DG_loss)\n",
    "\n",
    "    if it % 100 == 0:\n",
    "        update_tb_summary(it)"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Keras  WACGAN",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
