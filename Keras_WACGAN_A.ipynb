{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils.generic_utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND = 777\n",
    "\n",
    "RUN = 'A'\n",
    "OUT_DIR = 'out/' + RUN\n",
    "TENSORBOARD_DIR = '/tensorboard/wgans/' + RUN\n",
    "\n",
    "# GPU # \n",
    "GPU = \"0\"\n",
    "\n",
    "# latent vector size\n",
    "Z_SIZE = 100\n",
    "\n",
    "# number of iterations D is trained for per each G iteration\n",
    "D_ITERS = 5\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "ITERATIONS = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(OUT_DIR): os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use specific GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basically return mean(y_pred),\n",
    "# but with ability to inverse it for minimization (when y_true == -1)\n",
    "def wasserstein(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_D():\n",
    "\n",
    "    # weights are initlaized from normal distribution with below params\n",
    "    weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "    input_image = Input(shape=(28, 28, 1), name='input_image')\n",
    "\n",
    "    x = Conv2D(\n",
    "        32, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_1',\n",
    "        kernel_initializer=weight_init)(input_image)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        64, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_2',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        128, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_3',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        256, (3, 3),\n",
    "        padding='same',\n",
    "        name='coonv_4',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    features = Flatten()(x)\n",
    "\n",
    "    output_is_fake = Dense(\n",
    "        1, activation='linear', name='output_is_fake')(features)\n",
    "\n",
    "    output_class = Dense(\n",
    "        10, activation='softmax', name='output_class')(features)\n",
    "\n",
    "    return Model(\n",
    "        inputs=[input_image], outputs=[output_is_fake, output_class], name='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_G(Z_SIZE=Z_SIZE):\n",
    "    DICT_LEN = 10\n",
    "    EMBEDDING_LEN = Z_SIZE\n",
    "\n",
    "    # weights are initlaized from normal distribution with below params\n",
    "    weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "    # class#\n",
    "    input_class = Input(shape=(1, ), dtype='int32', name='input_class')\n",
    "    # encode class# to the same size as Z to use hadamard multiplication later on\n",
    "    e = Embedding(\n",
    "        DICT_LEN, EMBEDDING_LEN,\n",
    "        embeddings_initializer='glorot_uniform')(input_class)\n",
    "    embedded_class = Flatten(name='embedded_class')(e)\n",
    "\n",
    "    # latent var\n",
    "    input_z = Input(shape=(Z_SIZE, ), name='input_z')\n",
    "\n",
    "    # hadamard product\n",
    "    h = multiply([input_z, embedded_class], name='h')\n",
    "\n",
    "    # cnn part\n",
    "    x = Dense(1024)(h)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Dense(128 * 7 * 7)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Reshape((7, 7, 128))(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, (5, 5), padding='same', kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, (5, 5), padding='same', kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        1, (2, 2),\n",
    "        padding='same',\n",
    "        activation='tanh',\n",
    "        name='output_generated_image',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "\n",
    "    return Model(inputs=[input_z, input_class], outputs=x, name='G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "\n",
    "D = create_D()\n",
    "\n",
    "D.compile(\n",
    "    optimizer=RMSprop(lr=0.00005),\n",
    "    loss=[wasserstein, 'sparse_categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_z = Input(shape=(Z_SIZE, ), name='input_z_')\n",
    "input_class = Input(shape=(1, ),name='input_class_', dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "\n",
    "G = create_G()\n",
    "\n",
    "# create combined D(G) model\n",
    "# D.trainable = False\n",
    "output_is_fake, output_class = D(G(inputs=[input_z, input_class]))\n",
    "DG = Model(inputs=[input_z, input_class], outputs=[output_is_fake, output_class])\n",
    "DG.get_layer('D').trainable = False # freeze D in generator training faze\n",
    "\n",
    "DG.compile(\n",
    "    optimizer=RMSprop(lr=0.00005),\n",
    "    loss=[wasserstein, 'sparse_categorical_crossentropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f961900bb70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f967c2a40f0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try generating image\n",
    "z = np.random.randn(100).reshape(1, 100)\n",
    "img = G.predict([z, np.array([8])])\n",
    "plt.imshow(img.reshape((28, 28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get our mnist data, and force it to be of shape (..., 28, 28, 1) with\n",
    "# range [-1., 1.]\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "X_test = np.expand_dims(X_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num_samples, test_num_samples = X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write TensorBoard summaries\n",
    "\n",
    "sw = tf.summary.FileWriter(TENSORBOARD_DIR)\n",
    "\n",
    "\n",
    "def update_tb_summary(step):\n",
    "\n",
    "    s = tf.Summary()\n",
    "\n",
    "    # losses as is\n",
    "    for names, vals in zip((('D_true_is_fake', 'D_true_class'),\n",
    "                            ('D_fake_is_fake', 'D_fake_class'), ('DG_is_fake',\n",
    "                                                                 'DG_class')),\n",
    "                           (D_true_losses, D_fake_losses, DG_losses)):\n",
    "\n",
    "        v1 = s.value.add()\n",
    "        v1.simple_value = vals[-1][1]\n",
    "        v1.tag = names[0]\n",
    "\n",
    "        v1 = s.value.add()\n",
    "        v1.simple_value = vals[-1][2]\n",
    "        v1.tag = names[1]\n",
    "\n",
    "    # D loss: -1*D_true_is_fake - D_fake_is_fake\n",
    "    v = s.value.add()\n",
    "    v.simple_value = -D_true_losses[-1][1] - D_fake_losses[-1][1]\n",
    "    v.tag = 'D loss (-1*D_true_is_fake - D_fake_is_fake)'\n",
    "\n",
    "    # image\n",
    "\n",
    "    img = generate_samples(save=False)\n",
    "    s.MergeFromString(tf.Session().run(\n",
    "        tf.summary.image('generated_samples', img.reshape([1, *i.shape, 1]))))\n",
    "\n",
    "    sw.add_summary(s, step)\n",
    "    sw.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save 10x10 sample of generated images\n",
    "def generate_samples(n=0, save=True):\n",
    "    \n",
    "    zz = np.random.normal(0., 1., (100, Z_SIZE))\n",
    "    generated_classes = np.array(list(range(0, 10)) * 10)\n",
    "    generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "    rr = []\n",
    "    for c in range(10):\n",
    "        rr.append(\n",
    "            np.concatenate(generated_images[c * 10:(1 + c) * 10]).reshape(\n",
    "                280, 28))\n",
    "    img = np.hstack(rr)\n",
    "\n",
    "    if save:\n",
    "        plt.imsave(OUT_DIR + '/generated@%d.png' % n, img, cmap=plt.cm.gray)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    112/1000000 [..............................] - ETA: 1437882s - D_real_is_fake: -3.3770 - D_real_class: 1.3270 - D_fake_is_fake: 2.7789 - D_fake_class: 2.3825 - D(G)_is_fake: -2.2463 - D(G)_class: 2.3892"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-f25705ff337c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mD_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mD_fake_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fake = 1\n",
    "# real = -1\n",
    "\n",
    "progress_bar = Progbar(target=ITERATIONS)\n",
    "\n",
    "DG_losses = []\n",
    "D_true_losses = []\n",
    "D_fake_losses = []\n",
    "\n",
    "for it in range(ITERATIONS):\n",
    "\n",
    "    if len(D_true_losses) > 0:\n",
    "        progress_bar.update(\n",
    "            it,\n",
    "            values=[\n",
    "                    ('D_real_is_fake', np.mean(D_true_losses[-5:], axis=0)[1]),\n",
    "                    ('D_real_class', np.mean(D_true_losses[-5:], axis=0)[2]),\n",
    "                    ('D_fake_is_fake', np.mean(D_fake_losses[-5:], axis=0)[1]),\n",
    "                    ('D_fake_class', np.mean(D_fake_losses[-5:], axis=0)[2]),\n",
    "                    ('D(G)_is_fake', np.mean(DG_losses[-5:],axis=0)[1]),\n",
    "                    ('D(G)_class', np.mean(DG_losses[-5:],axis=0)[2])\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        progress_bar.update(it)\n",
    "\n",
    "    # 1: train D on real+generated images\n",
    "\n",
    "    if it < 25 or it % 500 == 0:\n",
    "        d_iters = 100\n",
    "    else:\n",
    "        d_iters = D_ITERS\n",
    "\n",
    "    for d_it in range(d_iters):\n",
    "\n",
    "        # unfreeze D\n",
    "        D.trainable = True\n",
    "        for l in D.layers: l.trainable = True\n",
    "\n",
    "        # clip D weights\n",
    "\n",
    "        for l in D.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "\n",
    "        # 1.1: maximize D output on reals === minimize -1*(D(real))\n",
    "\n",
    "        # draw random samples from real images\n",
    "        index = np.random.choice(train_num_samples, BATCH_SIZE, replace=False)\n",
    "        real_images = X_train[index]\n",
    "        real_images_classes = y_train[index]\n",
    "\n",
    "        D_loss = D.train_on_batch(real_images, [-np.ones(BATCH_SIZE), real_images_classes])\n",
    "        D_true_losses.append(D_loss)\n",
    "\n",
    "        # 1.2: minimize D output on fakes \n",
    "\n",
    "        zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE))\n",
    "        generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "        generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "        D_loss = D.train_on_batch(generated_images, [np.ones(BATCH_SIZE), generated_classes])\n",
    "        D_fake_losses.append(D_loss)\n",
    "\n",
    "    # 2: train D(G) (D is frozen)\n",
    "    # minimize D output while supplying it with fakes, telling it that they are reals (-1)\n",
    "\n",
    "    # freeze D\n",
    "    D.trainable = False\n",
    "    for l in D.layers: l.trainable = False\n",
    "\n",
    "    zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE)) \n",
    "    generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "\n",
    "    DG_loss = DG.train_on_batch(\n",
    "        [zz, generated_classes.reshape((-1, 1))],\n",
    "        [-np.ones(BATCH_SIZE), generated_classes])\n",
    "\n",
    "    DG_losses.append(DG_loss)\n",
    "\n",
    "#     if it % 250 == 0:\n",
    "#         generate_samples(it, save=True)\n",
    "        \n",
    "    if it % 2 == 0:\n",
    "        update_tb_summary(it)"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Keras  WACGAN",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
